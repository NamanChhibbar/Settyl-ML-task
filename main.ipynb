{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settyl Data Science And Machine Learning Engineer Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary modules and utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, numpy as np\n",
    "\n",
    "from utils import preprocess, train_test_split, tokenize, labels2tensor, dynamically_batch\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing and visualizing the dataset\n",
    "\n",
    "We laod the data from the json path below. Data is in the form of a list of dictionaries, each containing pair of values of external status and internal status. To visualize the data, we print the tail of the dataset (last 5 rows). We use the last 5 rows instead of the first 5 to check for any redundant rows that may have been loaded due to newlines at the end of the data file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'externalStatus': 'Import Loaded on Rail',\n",
       "  'internalStatus': 'Loaded on Vessel'},\n",
       " {'externalStatus': 'Full Transshipment Loaded',\n",
       "  'internalStatus': 'Loaded on Vessel'},\n",
       " {'externalStatus': 'Full Transshipment Loaded',\n",
       "  'internalStatus': 'Loaded on Vessel'},\n",
       " {'externalStatus': 'Export Loaded on Vessel',\n",
       "  'internalStatus': 'Loaded on Vessel'},\n",
       " {'externalStatus': 'Empty to Shipper',\n",
       "  'internalStatus': 'Empty Container Released'}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Path to json\n",
    "json_path = \"dataset.json\"\n",
    "\n",
    "# Loading the data\n",
    "with open(json_path) as fp:\n",
    "    data = json.load(fp)\n",
    "\n",
    "# Tail of the data\n",
    "data[-5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "To preprocess the data, we iterate over the pairs of external and internal statuses. We then strip off any white spaces and convert the texts to lower case. We also remove any non-alphanumeric characters for simplicity. Check the `preprocess` function in [utils.py](utils.py) for more details.\n",
    "\n",
    "We extract the inputs (external statuses), labels (internal statuses), unique labels, and vocabulary after preprocessing. Note that the vocabulary only contains distinct words from external statuses since internal statuses are treated as classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts, labels, unique_labels, vocab = preprocess(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "148"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Length of our vocabulary\n",
    "\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['arrival',\n",
       " 'departure',\n",
       " 'empty container released',\n",
       " 'empty return',\n",
       " 'gate in',\n",
       " 'gate out',\n",
       " 'inbound terminal',\n",
       " 'intransit',\n",
       " 'loaded on vessel',\n",
       " 'off rail',\n",
       " 'on rail',\n",
       " 'outbound terminal',\n",
       " 'port in',\n",
       " 'port out',\n",
       " 'unloaded on vessel']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unique labels in our dataset\n",
    "\n",
    "unique_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Maximum number of words in our texts\n",
    "\n",
    "max(map(lambda x: len(x.split()), texts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the data\n",
    "\n",
    "We split the data into train and test sets. We will use the train set for training and test set for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.8\n",
    "shuffle = True\n",
    "\n",
    "train_texts, train_labels, test_texts, test_labels = train_test_split(texts, labels, train_ratio, shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(977, 245)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lengths of train and test sets\n",
    "\n",
    "len(train_texts), len(test_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating tensor dataset\n",
    "\n",
    "The train data is dynamically batched (batching similar length sequences together) and the labels are vectorized. We dynamically batch our train set for efficient computations, since padding will be minimal. The test set in vectorized into one single batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_tokens = 12\n",
    "\n",
    "test_inputs, test_classes = tokenize(test_texts, vocab, max_tokens), labels2tensor(test_labels, unique_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[103, 119,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [103, 119,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [103, 119,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [103, 119,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [103, 119,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]]),\n",
       " tensor([ 1,  1, 14,  5,  1]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tail of vectorized test set\n",
    "\n",
    "test_inputs[-5:], test_classes[-5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will implement dynamic batching for train set. To do so, we sort the train texts by the number of tokens and batch accordingly. Refer [utils.py](utils.py) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "batched_train = dynamically_batch(train_texts, train_labels, batch_size, vocab, unique_labels, max_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor([[ 87, 104,  95, 130,  27],\n",
       "          [ 87, 104,  95, 130,  27],\n",
       "          [ 87, 104,  95, 130,  27],\n",
       "          [ 87, 104,  95, 130,  27],\n",
       "          [ 87, 104,  95, 130,  27],\n",
       "          [ 87, 104,  95, 130,  27],\n",
       "          [ 87, 104,  95, 130,  27],\n",
       "          [ 87, 104,  95, 130,  27],\n",
       "          [ 87, 104,  95, 130,  27],\n",
       "          [ 87, 104,  95, 130,  27],\n",
       "          [ 87, 104,  95, 130,  27],\n",
       "          [ 87, 104,  95, 130,  27],\n",
       "          [ 87, 104,  95, 130,  27],\n",
       "          [ 87, 104,  95, 130,  27],\n",
       "          [ 87, 104,  95, 130,  27],\n",
       "          [ 87, 104,  95, 130,  27],\n",
       "          [ 87, 104,  95, 130,  27],\n",
       "          [ 87, 104,  95, 130,  27],\n",
       "          [ 87, 104,  95, 130,  27],\n",
       "          [ 87, 104,  95, 130,  27],\n",
       "          [ 87, 104,  95, 130,  27],\n",
       "          [ 87, 104,  95, 130,  27],\n",
       "          [ 87, 104,  95, 130,  27],\n",
       "          [ 87, 104,  95, 130,  27],\n",
       "          [ 87, 104,  95, 130,  27],\n",
       "          [ 87, 104,  95, 130,  27],\n",
       "          [ 87, 104,  95, 130,  27],\n",
       "          [ 87, 104,  95, 130,  27],\n",
       "          [ 87, 104,  95, 130,  27],\n",
       "          [ 87, 104,  95, 130,  27],\n",
       "          [ 87, 104,  95, 130,  27],\n",
       "          [ 87, 104,  95, 130,  27]]),\n",
       "  tensor([ 8,  8,  8, 11,  8,  3, 11,  8,  8,  8,  8,  8,  0,  2,  2, 11,  8,  8,\n",
       "           8,  8,  8,  8,  8,  8,  8,  8,  8,  0,  8,  8,  8,  0])),\n",
       " (tensor([[ 87, 104,  92,  90,  18],\n",
       "          [ 87, 104,  92,  90,  18],\n",
       "          [ 87, 104,  92,  90,  18],\n",
       "          [ 87, 104,  92,  90,  18],\n",
       "          [ 87, 104,  92,  90,  18],\n",
       "          [ 87, 104,  92,  90,  18],\n",
       "          [ 87, 104,  92,  90,  18],\n",
       "          [ 87, 104,  92,  90,  18],\n",
       "          [ 87, 104,  92,  90,  18],\n",
       "          [ 87, 104,  92,  90,  18],\n",
       "          [ 87, 104,  92,  90,  18],\n",
       "          [ 87, 104,  92,  90,  18],\n",
       "          [ 87, 104,  92,  90,  18],\n",
       "          [ 87, 104,  92,  90,  18],\n",
       "          [ 87, 104,  92,  90,  18],\n",
       "          [ 87, 104,  92,  90,  18],\n",
       "          [ 87, 104,  92,  90,  18],\n",
       "          [ 87, 104,  92,  90,  18],\n",
       "          [ 87, 104,  92,  90,  18],\n",
       "          [ 87, 104,  92,  90,  18],\n",
       "          [ 87, 104,  92,  90,  18],\n",
       "          [ 87, 104,  92,  90,  18],\n",
       "          [ 87, 104,  92,  90,  18],\n",
       "          [ 87, 104,  92,  90,  18],\n",
       "          [ 87, 104,  92,  90,  18],\n",
       "          [ 87, 104,  92,  90,  18],\n",
       "          [ 87, 104,  92,  90,  18],\n",
       "          [ 87, 104,  92,  90,  18],\n",
       "          [ 87, 104,  92,  90,  18],\n",
       "          [ 87, 104,  92,  90,  18],\n",
       "          [ 87, 104,  92,  90,  18],\n",
       "          [ 87, 104,  92,  90,  18]]),\n",
       "  tensor([ 8,  2,  8,  3,  8,  8,  8,  2,  8, 11,  8,  8,  8,  8,  8,  8,  8,  8,\n",
       "           8,  8,  8,  8,  8,  3,  8,  8,  8,  8,  8,  8,  2,  8])),\n",
       " (tensor([[ 63,  32, 111, 102,  49,   0],\n",
       "          [ 63,  32, 111, 102,  49,   0],\n",
       "          [ 63,  32, 111, 102,  49,   0],\n",
       "          [ 63,  32, 111, 102,  49,   0],\n",
       "          [ 63,  32, 111, 102,  49,   0],\n",
       "          [ 63,  32, 111, 102,  49,   0],\n",
       "          [ 63,  32, 111, 102,  49,   0],\n",
       "          [ 63,  32, 111, 102,  49,   0],\n",
       "          [ 63,  32, 111, 102,  49,   0],\n",
       "          [ 63,  32, 111, 102,  49,   0],\n",
       "          [ 63,  32, 111, 102,  49,   0],\n",
       "          [ 63,  32, 111, 102,  49,   0],\n",
       "          [ 63,  32, 111, 102,  49,   0],\n",
       "          [ 63,  32, 111, 102,  49,   0],\n",
       "          [ 63,  32, 111, 102,  49,   0],\n",
       "          [ 63,  32, 111, 102,  49,   0],\n",
       "          [ 63,  32, 111, 102,  49,   0],\n",
       "          [ 63,  32, 111, 102,  49,   0],\n",
       "          [ 63,  32, 111, 102,  49,   0],\n",
       "          [ 63,  32, 111, 102,  49,   0],\n",
       "          [ 63,  32, 111, 102,  49,   0],\n",
       "          [ 63,  32, 111, 102,  49,   0],\n",
       "          [ 63,  32, 111, 102,  49,   0],\n",
       "          [ 63,  32, 111, 102,  49,   0],\n",
       "          [ 63,  32, 111, 102,  49,   0],\n",
       "          [ 63,  32, 111, 102,  49,   0],\n",
       "          [ 63,  32, 111, 102,  49,   0],\n",
       "          [ 63,  32, 111, 102,  49,   0],\n",
       "          [ 63,  32, 111, 102,  49,   0],\n",
       "          [ 63,  32, 111, 102,  49,   0],\n",
       "          [ 63,  32, 111, 102,  49,   0],\n",
       "          [ 63,  32, 111, 102,  49,   0]]),\n",
       "  tensor([0, 8, 8, 8, 8, 8, 8, 0, 8, 8, 8, 8, 8, 8, 8, 1, 8, 1, 1, 0, 1, 1, 1, 0,\n",
       "          0, 8, 0, 8, 0, 8, 8, 0])),\n",
       " (tensor([[ 88, 104,  36, 145,  97, 144,  90,   0,   0,   0,   0,   0],\n",
       "          [ 88, 104,  36, 145,  97, 144,  90,   0,   0,   0,   0,   0],\n",
       "          [ 88, 104,  36, 145,  97, 144,  90,   0,   0,   0,   0,   0],\n",
       "          [ 88, 104,  36, 145,  97, 144,  90,   0,   0,   0,   0,   0],\n",
       "          [ 88, 104,  36, 145,  97, 144,  90,   0,   0,   0,   0,   0],\n",
       "          [ 88, 104,  36, 145,  97, 144,  90,   0,   0,   0,   0,   0],\n",
       "          [ 88, 104,  36, 145,  97, 144,  90,   0,   0,   0,   0,   0],\n",
       "          [ 88, 104,  36, 145,  97, 144,  90,   0,   0,   0,   0,   0],\n",
       "          [ 88, 104,  36, 145,  97, 144,  90,   0,   0,   0,   0,   0],\n",
       "          [ 88, 104,  36, 145,  97, 144,  90,   0,   0,   0,   0,   0],\n",
       "          [ 88, 104,  36, 145,  97, 144,  90,   0,   0,   0,   0,   0],\n",
       "          [ 88, 104,  36, 145,  97, 144,  90,   0,   0,   0,   0,   0],\n",
       "          [ 88, 104,  36, 145,  97, 144,  90,   0,   0,   0,   0,   0],\n",
       "          [ 88, 104,  36, 145,  97, 144,  90,   0,   0,   0,   0,   0],\n",
       "          [ 88, 104,  36, 145,  97, 144,  90,   0,   0,   0,   0,   0],\n",
       "          [ 88, 104,  36, 145,  97, 144,  90,   0,   0,   0,   0,   0],\n",
       "          [ 88, 104,  36, 145,  97, 144,  90,   0,   0,   0,   0,   0],\n",
       "          [ 88, 104,  36, 145,  97, 144,  90,   0,   0,   0,   0,   0],\n",
       "          [ 88, 104,  36, 145,  97, 144,  90,   0,   0,   0,   0,   0],\n",
       "          [ 88, 104,  36, 145,  97, 144,  90,   0,   0,   0,   0,   0],\n",
       "          [ 88, 104,  36, 145,  97, 144,  90,   0,   0,   0,   0,   0],\n",
       "          [ 88, 104,  36, 145,  97, 144,  90,   0,   0,   0,   0,   0],\n",
       "          [ 88, 104,  36, 145,  97, 144,  90,   0,   0,   0,   0,   0],\n",
       "          [ 88, 104,  36, 145,  97, 144,  90,   0,   0,   0,   0,   0],\n",
       "          [ 88, 104,  36, 145,  97, 144,  90,   0,   0,   0,   0,   0],\n",
       "          [ 88, 104,  36, 145,  97, 144,  90,   0,   0,   0,   0,   0],\n",
       "          [ 88, 104,  36, 145,  97, 144,  90,   0,   0,   0,   0,   0],\n",
       "          [ 88, 104,  36, 145,  97, 144,  90,   0,   0,   0,   0,   0],\n",
       "          [ 88, 104,  36, 145,  97, 144,  90,   0,   0,   0,   0,   0],\n",
       "          [ 88, 104,  36, 145,  97, 144,  90,   0,   0,   0,   0,   0],\n",
       "          [ 88, 104,  36, 145,  97, 144,  90,   0,   0,   0,   0,   0],\n",
       "          [ 88, 104,  36, 145,  97, 144,  90,   0,   0,   0,   0,   0]]),\n",
       "  tensor([ 8,  8,  8,  8,  8,  8,  8,  0,  1,  8,  1,  0, 14,  1,  0,  0,  1,  0,\n",
       "           1,  0,  1,  1,  0,  1,  1,  0,  0,  0,  1,  1,  0,  8])),\n",
       " (tensor([[ 88, 104,  91, 105,   2,  34, 116, 102,  89,  91, 105,   2],\n",
       "          [ 88, 104,  91, 105,   2,  34, 116, 102,  89,  91, 105,   2],\n",
       "          [ 88, 104,  91, 105,   2,  34, 116, 102,  89,  91, 105,   2],\n",
       "          [ 88, 104,  91, 105,   2,  34, 116, 102,  89,  91, 105,   2],\n",
       "          [ 88, 104,  91, 105,   2,  34, 116, 102,  89,  91, 105,   2],\n",
       "          [ 88, 104,  91, 105,   2,  34, 116, 102,  89,  91, 105,   2],\n",
       "          [ 88, 104,  91, 105,   2,  34, 116, 102,  89,  91, 105,   2],\n",
       "          [ 88, 104,  91, 105,   2,  34, 116, 102,  89,  91, 105,   2],\n",
       "          [ 88, 104,  91, 105,   2,  34, 116, 102,  89,  91, 105,   2],\n",
       "          [ 88, 104,  91, 105,   2,  34, 116, 102,  89,  91, 105,   2],\n",
       "          [ 88, 104,  91, 105,   2,  34, 116, 102,  89,  91, 105,   2],\n",
       "          [ 88, 104,  91, 105,   2,  34, 116, 102,  89,  91, 105,   2],\n",
       "          [ 88, 104,  91, 105,   2,  34, 116, 102,  89,  91, 105,   2],\n",
       "          [ 88, 104,  91, 105,   2,  34, 116, 102,  89,  91, 105,   2],\n",
       "          [ 88, 104,  91, 105,   2,  34, 116, 102,  89,  91, 105,   2],\n",
       "          [ 88, 104,  91, 105,   2,  34, 116, 102,  89,  91, 105,   2],\n",
       "          [ 88, 104,  91, 105,   2,  34, 116, 102,  89,  91, 105,   2]]),\n",
       "  tensor([ 8,  8, 14, 14, 14,  8,  8, 14, 14,  8,  8, 14, 14,  8,  8,  8, 14]))]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tail of the dynamically batched train set\n",
    "\n",
    "batched_train[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
